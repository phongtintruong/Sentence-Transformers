{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Thanks for the internet so i can write this line\n",
      "(384,)\n",
      "\n",
      "Sentence: Internet help me to access almost every knowledges in this world, include this tutorial\n",
      "(384,)\n",
      "\n",
      "Sentence: I can write this line because of internet\n",
      "(384,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Sentences we like to encode\n",
    "sentences = ['Thanks for the internet so i can write this line',\n",
    "             'Internet help me to access almost every knowledges in this world, include this tutorial',\n",
    "            #  \"I'm really greatful for knowing this tutorial!\"\n",
    "             'I can write this line because of internet']\n",
    "\n",
    "# Sentences are encoder by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Print the embeddings\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "  print(\"Sentence:\", sentence)\n",
    "  # print(\"Embedding:\", embedding)\n",
    "  print(embedding.shape) #(384,)-fixed sized vector\n",
    "  print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Sentence Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity of [Thanks for the internet so i can write this line] and [Internet help me to access almost every knowledges in this world, include this tutorial]: tensor([[0.2462]])\n",
      "Cosine similarity of [Thanks for the internet so i can write this line] and [I can write this line because of internet]: tensor([[0.7547]])\n",
      "Cosine similarity of [Internet help me to access almost every knowledges in this world, include this tutorial] and [I can write this line because of internet]: tensor([[0.3230]])\n"
     ]
    }
   ],
   "source": [
    "# Cosine similarity of each pair in three sentences above\n",
    "for id1 in range(3):\n",
    "  for id2 in range(id1+1, 3):\n",
    "    print(\"Cosine similarity of [\" + sentences[id1] + \"] and [\" + sentences[id2] + \"]:\", str(util.cos_sim(embeddings[id1], embeddings[id2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 most similar pairs:\n",
      "A man is eating food. \t A man is eating a piece of bread. \t 0.7553\n",
      "A man is riding a horse. \t A man is riding a white horse on an enclosed ground. \t 0.7369\n",
      "A monkey is playing drums. \t Someone in a gorilla costume is playing a set of drums. \t 0.6433\n",
      "A woman is playing violin. \t Someone in a gorilla costume is playing a set of drums. \t 0.2564\n",
      "A man is eating food. \t A man is riding a horse. \t 0.2474\n"
     ]
    }
   ],
   "source": [
    "# Another way to compute cosine similarity between all pairs of sentences\n",
    "new_sentences = ['A man is eating food.',\n",
    "          'A man is eating a piece of bread.',\n",
    "          'The girl is carrying a baby.',\n",
    "          'A man is riding a horse.',\n",
    "          'A woman is playing violin.',\n",
    "          'Two men pushed carts through the woods.',\n",
    "          'A man is riding a white horse on an enclosed ground.',\n",
    "          'A monkey is playing drums.',\n",
    "          'Someone in a gorilla costume is playing a set of drums.']\n",
    "\n",
    "#Encode all sentences\n",
    "new_embeddings = model.encode(new_sentences)\n",
    "\n",
    "#Compute cosine similarity between all pairs\n",
    "cos_sim = util.cos_sim(new_embeddings, new_embeddings)\n",
    "\n",
    "#Add all pairs to a list with their cosine similarity score\n",
    "all_sentence_combinations = []\n",
    "for i in range(len(cos_sim)-1):\n",
    "    for j in range(i+1, len(cos_sim)):\n",
    "        all_sentence_combinations.append([cos_sim[i][j], i, j])\n",
    "\n",
    "#Sort list by the highest cosine similarity score\n",
    "all_sentence_combinations = sorted(all_sentence_combinations, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "print(\"Top-5 most similar pairs:\")\n",
    "for score, i, j in all_sentence_combinations[0:5]:\n",
    "    print(\"{} \\t {} \\t {:.4f}\".format(new_sentences[i], new_sentences[j], cos_sim[i][j]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 9])\n"
     ]
    }
   ],
   "source": [
    "print(cos_sim.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NTT-CLEAR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

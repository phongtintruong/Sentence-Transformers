{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There're a lot of pretrained models can be found suitable for several tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Search\n",
    "Given a question/search query, the model can find relevant text passages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: tensor([[0.2438, 0.3479, 0.0650, 0.2787, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "semantic_search_model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "# query_embedding = semantic_search_model.encode(\"what's the best way to live?\")\n",
    "# passage_embedding = semantic_search_model.encode([\"You should live in the moment. Don't dwell on the past or worry about the future. Live for today!\",\n",
    "#                                   \"Everybody dies, but not everybody lives\"])\n",
    "\n",
    "query_embedding = semantic_search_model.encode(\"Get min and max string of list\")\n",
    "passage_embedding = semantic_search_model.encode([\"java.util.Optional.get\",\n",
    "                                                  \"java.util.stream.Collectors.maxBy\",\n",
    "                                                  \"java.awt.Rectangle.intersects\",\n",
    "                                                  \"java.lang.String.split\",\n",
    "                                                  \"Get min and max string of list\"]) # the model does not have the knowledge of the query, need to be fine-tuned\n",
    "\n",
    "print(\"Similarity score:\", util.dot_score(query_embedding, passage_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><u>note:</u></i> The first 2 should be the most relevants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-QA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several models have been trained on 215M QA pairs from various sources and domains.\n",
    "\n",
    "These model perform well on many search tasks and domains.(e.g., semantic search)\n",
    "- Some were tuned to be used with dot-product\n",
    "- Some produce normalized vectors of length 1, which can be used with dot-product, cosine-similarity and Euclidean distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model tuned to be used with dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: tensor([[44.9437, 36.3805, 43.5505]])\n"
     ]
    }
   ],
   "source": [
    "mul_qa_dot_model = SentenceTransformer('multi-qa-MiniLM-L6-dot-v1')\n",
    "# query_embedding = mul_qa_dot_model.encode(\"Get min and max string of list\")\n",
    "# passage_embedding = mul_qa_dot_model.encode([\"java.util.Optional.get\",\n",
    "#                                             \"java.util.stream.Collectors.maxBy\",\n",
    "#                                             \"java.awt.Rectangle.intersects\",\n",
    "#                                             \"java.lang.String.split\",\n",
    "#                                             \"Get min and max string of list\"]) # the model does not have the knowledge of the query, need to be fine-tuned\n",
    "\n",
    "query_embedding = mul_qa_dot_model.encode(\"How many people live in London?\")\n",
    "passage_embedding = mul_qa_dot_model.encode([\"Around 9 million people live in London\",\n",
    "                                             \"London is known for its financial district\",\n",
    "                                             \"How many people live in London?\"])\n",
    "\n",
    "print(\"Similarity score:\", util.dot_score(query_embedding, passage_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===> The answer for the query get the score better than the query itself. ===> Model was trained for q&a purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<-----=-----> TODO Why the dot_score's bigger than 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: tensor([[32.6886, 36.7602, 29.2752, 32.7594, 49.1859]])\n"
     ]
    }
   ],
   "source": [
    "mul_qa_dot_model = SentenceTransformer('multi-qa-MiniLM-L6-dot-v1')\n",
    "query_embedding = mul_qa_dot_model.encode(\"Get min and max string of list\")\n",
    "passage_embedding = mul_qa_dot_model.encode([\"java.util.Optional.get\",\n",
    "                                            \"java.util.stream.Collectors.maxBy\",\n",
    "                                            \"java.awt.Rectangle.intersects\",\n",
    "                                            \"java.lang.String.split\",\n",
    "                                            \"Get min and max string of list\"]) # the model does not have the knowledge of the query, need to be fine-tuned\n",
    "\n",
    "print(\"Similarity score:\", util.dot_score(query_embedding, passage_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><u>note:</u></i> The first 2 should be the most relevants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model normalized vectors of length 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: tensor([[0.8800, 0.4522, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "mul_qa_cos_model = SentenceTransformer('multi-qa-distilbert-cos-v1')\n",
    "\n",
    "query_embedding = mul_qa_cos_model.encode(\"How many people live in London?\")\n",
    "passage_embedding = mul_qa_cos_model.encode([\"Around 9 million people live in London.\",\n",
    "                                                \"London is known for its financial district\",\n",
    "                                                \"How many people live in London?\"])\n",
    "print(\"Similarity score:\", util.dot_score(query_embedding, passage_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===> dot_score of the query itself is always 1 ===> The model was trained for semantic comparing purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: tensor([[32.6886, 36.7602, 29.2752, 32.7594, 49.1859]])\n"
     ]
    }
   ],
   "source": [
    "mul_qa_cos_model = SentenceTransformer('multi-qa-distilbert-cos-v1')\n",
    "\n",
    "query_embedding = mul_qa_dot_model.encode(\"Get min and max string of list\")\n",
    "passage_embedding = mul_qa_dot_model.encode([\"java.util.Optional.get\",\n",
    "                                            \"java.util.stream.Collectors.maxBy\",\n",
    "                                            \"java.awt.Rectangle.intersects\",\n",
    "                                            \"java.lang.String.split\",\n",
    "                                            \"Get min and max string of list\"]) # the model does not have the knowledge of the query, need to be fine-tuned\n",
    "\n",
    "print(\"Similarity score:\", util.dot_score(query_embedding, passage_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><u>note:</u></i> The first 2 should be the most relevants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MSMARCO Passage Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSMARCO Passage Ranking Dataset contains 500k real queries. Models also perform well on other domains.\n",
    "- Some were tuned to be used with dot-product\n",
    "- Some produce normalized vectors of length 1, which can be used with dot-product, cosine-similarity and Euclidean distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model tuned to be use with dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: tensor([[87.0118, 71.3875, 86.9643]])\n"
     ]
    }
   ],
   "source": [
    "msmarco_dot_model = SentenceTransformer('msmarco-distilbert-dot-v5')\n",
    "\n",
    "query_embedding = msmarco_dot_model.encode(\"How many people live in London?\")\n",
    "passage_embedding = msmarco_dot_model.encode([\"Around 9 million people live in London.\",\n",
    "                                                \"London is known for its financial district\",\n",
    "                                                \"How many people live in London?\"])\n",
    "print(\"Similarity score:\", util.dot_score(query_embedding, passage_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===> The answer for the query get the score better than the query itself. ===> Model was trained for q&a purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: tensor([[64.9078, 69.4863, 61.9641, 70.2112, 93.0185]])\n"
     ]
    }
   ],
   "source": [
    "msmarco_dot_model = SentenceTransformer('msmarco-distilbert-dot-v5')\n",
    "\n",
    "query_embedding = msmarco_dot_model.encode(\"Get min and max string of list\")\n",
    "passage_embedding = msmarco_dot_model.encode([\"java.util.Optional.get\",\n",
    "                                            \"java.util.stream.Collectors.maxBy\",\n",
    "                                            \"java.awt.Rectangle.intersects\",\n",
    "                                            \"java.lang.String.split\",\n",
    "                                            \"Get min and max string of list\"]) # the model does not have the knowledge of the query, need to be fine-tuned\n",
    "\n",
    "print(\"Similarity score:\", util.dot_score(query_embedding, passage_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><u>note:</u></i> The first 2 should be the most relevants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model normalized vectors of length 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: tensor([[0.9593, 0.3506, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "msmarco_cos_model = SentenceTransformer('msmarco-distilbert-cos-v5')\n",
    "\n",
    "query_embedding = msmarco_cos_model.encode(\"How many people live in London?\")\n",
    "passage_embedding = msmarco_cos_model.encode([\"Around 9 million people live in London.\",\n",
    "                                                \"London is known for its financial district\",\n",
    "                                                \"How many people live in London?\"])\n",
    "\n",
    "print(\"Similarity score:\", util.dot_score(query_embedding, passage_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===> dot_score of the query itself is always 1 ===> The model was trained for semantic comparing purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: tensor([[0.2284, 0.3320, 0.0240, 0.3599, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "msmarco_cos_model = SentenceTransformer('msmarco-distilbert-cos-v5')\n",
    "\n",
    "query_embedding = msmarco_cos_model.encode(\"Get min and max string of list\")\n",
    "passage_embedding = msmarco_cos_model.encode([\"java.util.Optional.get\",\n",
    "                                            \"java.util.stream.Collectors.maxBy\",\n",
    "                                            \"java.awt.Rectangle.intersects\",\n",
    "                                            \"java.lang.String.split\",\n",
    "                                            \"Get min and max string of list\"]) # the model does not have the knowledge of the query, need to be fine-tuned\n",
    "\n",
    "print(\"Similarity score:\", util.dot_score(query_embedding, passage_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><u>note:</u></i> The first 2 should be the most relevants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ===> By normalized vectors of length 1, cos model always see the query itself as the most relevant, while dot model see the answer for the query as the most relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ===> All the experiment models are still not good enough for downstream task (e.g., API recommendation) (Multi-QA models are a little bit better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Lingual Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image & Text-Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NTT-CLEAR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
